{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b8c38817",
      "metadata": {},
      "source": [
        "# ECON7890 Assignment 4 ? Kowloon Property Transactions\n",
        "\n",
        "End-to-end notebook: import/clean the 28hse Kowloon transactions (Nov 2014?Nov 2020), merge macro data, explore, model price drivers, and summarize findings.\n",
        "\n",
        "**Tasks**\n",
        "- Import & clean the raw CSV, fix headers, parse numbers, handle missing values\n",
        "- Merge with external macro indicators (World Bank unemployment & CPI)\n",
        "- Exploratory data analysis with descriptive stats and visuals\n",
        "- Train/evaluate multiple models to explain price per saleable sqft\n",
        "- Summarize insights and next steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0db97575",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'Excercises\\\\assignment4_outputs'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m DATA_PATH = Path(\u001b[33m'\u001b[39m\u001b[33mExcercises/hw.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m OUTPUT_DIR = Path(\u001b[33m'\u001b[39m\u001b[33mExcercises/assignment4_outputs\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\betoq\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pathlib\\_local.py:722\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    719\u001b[39m \u001b[33;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[32m    720\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m    724\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'Excercises\\\\assignment4_outputs'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "DATA_PATH = Path('Excercises/hw.csv')\n",
        "OUTPUT_DIR = Path('Excercises/assignment4_outputs')\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a12ad15d",
      "metadata": {},
      "source": [
        "## 1) Load raw data\n",
        "Read the provided `hw.csv` file and inspect the columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347abb23",
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_df = pd.read_csv(DATA_PATH)\n",
        "display(raw_df.head())\n",
        "print(f\"Rows: {len(raw_df):,}, Columns: {len(raw_df.columns)}\")\n",
        "raw_df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce5e4371",
      "metadata": {},
      "source": [
        "## 2) Cleaning helpers\n",
        "The raw headers are cryptic and some fields embed units/HTML. Helper functions below parse numbers, percentages, and holding periods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1a2b2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _parse_number(text: Any) -> float:\n",
        "    # Extract first numeric value from a string; return NaN on failure.\n",
        "    if pd.isna(text):\n",
        "        return np.nan\n",
        "    match = re.search(r\"([0-9]*\\.?[0-9]+)\", str(text))\n",
        "    if match:\n",
        "        try:\n",
        "            return float(match.group(1))\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def _parse_percent(text: Any) -> float:\n",
        "    # Convert percent strings (e.g., '413%') to decimal (4.13).\n",
        "    if pd.isna(text):\n",
        "        return np.nan\n",
        "    text = str(text).replace('%', '').strip()\n",
        "    if not text or text == '--':\n",
        "        return np.nan\n",
        "    try:\n",
        "        return float(text) / 100.0\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "def _parse_holding_years(text: Any) -> float:\n",
        "    # Convert holding period text such as '16 years 251 days' into years.\n",
        "    if pd.isna(text):\n",
        "        return np.nan\n",
        "    if text in ('--', '-1'):\n",
        "        return np.nan\n",
        "    text = str(text)\n",
        "    years = _parse_number(text)\n",
        "    days_match = re.search(r\"([0-9]+)\\s*day\", text)\n",
        "    days = float(days_match.group(1)) if days_match else 0.0\n",
        "    if np.isnan(years):\n",
        "        return days / 365.0 if days else np.nan\n",
        "    return years + days / 365.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3834f816",
      "metadata": {},
      "source": [
        "## 3) Clean transactions\n",
        "- Drop unnamed columns\n",
        "- Rename to readable headers\n",
        "- Parse dates, numbers, areas, floor, holding period, win/loss\n",
        "- Remove bad rows and duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c355cfa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_transactions(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    df = df.drop(columns=[c for c in df.columns if c.startswith('Unnamed')], errors='ignore')\n",
        "    rename_map: Dict[str, str] = {\n",
        "        'withpre': 'pre_sale_flag',\n",
        "        'catname': 'estate',\n",
        "        'catfathername': 'district',\n",
        "        'price': 'price_label',\n",
        "        'price_value': 'price_hkd',\n",
        "        'holddate': 'holding_period_text',\n",
        "        'winloss': 'winloss_pct',\n",
        "        'act_area': 'saleable_area',\n",
        "        'area': 'gross_area',\n",
        "        'arearaw': 'gross_area_raw',\n",
        "        'sq_price': 'sq_price_label',\n",
        "        'sq_price_value': 'price_per_gross_sf',\n",
        "        'sq_actprice': 'sq_actprice_label',\n",
        "        'sq_actprice_value': 'price_per_saleable_sf',\n",
        "        'date_y': 'year_text',\n",
        "        'state': 'building',\n",
        "        'addr': 'address',\n",
        "    }\n",
        "    df = df.rename(columns=rename_map)\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['pre_sale_flag'] = df['pre_sale_flag'].fillna(0).astype(int)\n",
        "    df['price_hkd'] = pd.to_numeric(df['price_hkd'], errors='coerce')\n",
        "    df['price_per_gross_sf'] = pd.to_numeric(df['price_per_gross_sf'], errors='coerce')\n",
        "    df['price_per_saleable_sf'] = pd.to_numeric(df['price_per_saleable_sf'], errors='coerce')\n",
        "\n",
        "    df['saleable_area'] = df['saleable_area'].apply(_parse_number)\n",
        "    df['gross_area'] = df['gross_area'].apply(_parse_number)\n",
        "    gross_series = df['gross_area_raw'] if 'gross_area_raw' in df.columns else pd.Series(np.nan, index=df.index)\n",
        "    df['gross_area_raw'] = pd.to_numeric(gross_series, errors='coerce')\n",
        "\n",
        "    df['floor_num'] = df['floor'].apply(_parse_number)\n",
        "    df['holding_period_years'] = df['holding_period_text'].apply(_parse_holding_years)\n",
        "    df['winloss_pct'] = df['winloss_pct'].apply(_parse_percent)\n",
        "\n",
        "    df['price_per_saleable_sf'] = df['price_per_saleable_sf'].fillna(\n",
        "        df['price_hkd'] / df['saleable_area']\n",
        "    )\n",
        "\n",
        "    df = df.dropna(subset=['date', 'price_hkd', 'saleable_area', 'price_per_saleable_sf', 'district', 'estate'])\n",
        "    df = df[(df['saleable_area'] > 0) & (df['price_hkd'] > 0) & (df['price_per_saleable_sf'] > 0)]\n",
        "\n",
        "    df['estate'] = df['estate'].astype(str).str.strip()\n",
        "    df['district'] = df['district'].astype(str).str.strip()\n",
        "    df['building'] = df['building'].astype(str).str.strip()\n",
        "\n",
        "    if 'id' in df.columns:\n",
        "        df = df.drop_duplicates(subset=['id'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "cleaned_df = clean_transactions(raw_df)\n",
        "display(cleaned_df.head())\n",
        "print(f\"Cleaned rows: {len(cleaned_df):,}\")\n",
        "cleaned_df.to_csv(OUTPUT_DIR / 'cleaned_transactions.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdaf83be",
      "metadata": {},
      "source": [
        "## 4) Macro data (World Bank)\n",
        "Pull Hong Kong unemployment rate (`SL.UEM.TOTL.ZS`) and CPI (`FP.CPI.TOTL`, 2010=100) and merge by year.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3afed7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_world_bank_indicator(indicator_id: str, value_name: str, start_year: int = 2014, end_year: int = 2020) -> pd.DataFrame:\n",
        "    url = f\"https://api.worldbank.org/v2/country/HKG/indicator/{indicator_id}?per_page=500&format=json\"\n",
        "    resp = requests.get(url, timeout=30)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    if len(data) < 2 or not isinstance(data[1], list):\n",
        "        raise ValueError(f\"Unexpected World Bank response for {indicator_id}\")\n",
        "    records: List[Dict[str, float]] = []\n",
        "    for entry in data[1]:\n",
        "        year_txt = entry.get('date')\n",
        "        value = entry.get('value')\n",
        "        if value is None or year_txt is None:\n",
        "            continue\n",
        "        try:\n",
        "            year = int(year_txt)\n",
        "        except ValueError:\n",
        "            continue\n",
        "        if start_year <= year <= end_year:\n",
        "            records.append({'year': year, value_name: float(value)})\n",
        "    out = pd.DataFrame(records).sort_values('year').reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_macro_dataset(start_year: int = 2014, end_year: int = 2020) -> pd.DataFrame:\n",
        "    unemployment = fetch_world_bank_indicator('SL.UEM.TOTL.ZS', 'unemployment_rate', start_year, end_year)\n",
        "    cpi = fetch_world_bank_indicator('FP.CPI.TOTL', 'cpi_index', start_year, end_year)\n",
        "    return pd.merge(unemployment, cpi, on='year', how='outer')\n",
        "\n",
        "\n",
        "macro_df = build_macro_dataset(2014, 2020)\n",
        "display(macro_df)\n",
        "macro_df.to_csv(OUTPUT_DIR / 'macro_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ff6a7f",
      "metadata": {},
      "source": [
        "## 5) Merge transactions + macro\n",
        "Merge on year to enrich each transaction with unemployment/CPI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81e9f30",
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df = pd.merge(cleaned_df, macro_df, on='year', how='left')\n",
        "display(merged_df[['date', 'district', 'price_hkd', 'saleable_area', 'price_per_saleable_sf', 'unemployment_rate', 'cpi_index']].head())\n",
        "merged_df.to_csv(OUTPUT_DIR / 'transactions_with_macro.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b92628e",
      "metadata": {},
      "source": [
        "## 6) Exploratory Data Analysis\n",
        "- Summary stats & missing values\n",
        "- Top districts by count\n",
        "- Distribution and scatter plots\n",
        "- Monthly median price trend and yearly macro overlay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66456724",
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = ['price_hkd', 'saleable_area', 'gross_area', 'price_per_saleable_sf', 'price_per_gross_sf']\n",
        "summary_stats = merged_df[numeric_cols].describe()\n",
        "missing = merged_df[numeric_cols].isna().sum().sort_values(ascending=False)\n",
        "top_districts = merged_df['district'].value_counts().head(10)\n",
        "\n",
        "display(summary_stats)\n",
        "display(missing)\n",
        "display(top_districts)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(x=merged_df['price_per_saleable_sf'], bins=50, kde=True, color='steelblue')\n",
        "plt.xlabel('Price per saleable sqft (HKD)')\n",
        "plt.title('Distribution of price per saleable sqft')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(\n",
        "    data=merged_df.sample(min(len(merged_df), 5000), random_state=42),\n",
        "    x='saleable_area', y='price_per_saleable_sf', hue='district', alpha=0.6, legend=False\n",
        ")\n",
        "plt.title('Saleable area vs price per sqft')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "monthly = merged_df.set_index('date')['price_per_saleable_sf'].resample('ME').median().dropna()\n",
        "monthly.plot(figsize=(9, 4), title='Monthly median price per saleable sqft')\n",
        "plt.ylabel('HKD per sqft')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "yearly = (\n",
        "    merged_df.groupby('year')\n",
        "    .agg(median_price_per_saleable_sf=('price_per_saleable_sf', 'median'), unemployment_rate=('unemployment_rate', 'median'))\n",
        "    .dropna()\n",
        ")\n",
        "if not yearly.empty:\n",
        "    fig, ax1 = plt.subplots(figsize=(9, 4))\n",
        "    ax1.plot(yearly.index, yearly['median_price_per_saleable_sf'], marker='o', color='tab:blue', label='Median price/sf')\n",
        "    ax1.set_ylabel('Median price per saleable sqft (HKD)', color='tab:blue')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(yearly.index, yearly['unemployment_rate'], marker='s', color='tab:red', label='Unemployment rate')\n",
        "    ax2.set_ylabel('Unemployment rate (%)', color='tab:red')\n",
        "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "    plt.title('Yearly price per sqft vs unemployment')\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11974a1c",
      "metadata": {},
      "source": [
        "## 7) Modeling price per saleable sqft\n",
        "Two models: linear regression (baseline) and random forest. Features include size, floor, holding period, win/loss, macro indicators, and district (one-hot).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e583f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "target = 'price_per_saleable_sf'\n",
        "feature_columns = [\n",
        "    'saleable_area', 'gross_area', 'floor_num', 'holding_period_years', 'winloss_pct',\n",
        "    'pre_sale_flag', 'unemployment_rate', 'cpi_index', 'year', 'district'\n",
        "]\n",
        "\n",
        "model_df = merged_df.dropna(subset=feature_columns + [target]).copy()\n",
        "X = model_df[feature_columns]\n",
        "y = model_df[target]\n",
        "\n",
        "categorical_cols = ['district']\n",
        "numeric_cols = [c for c in feature_columns if c not in categorical_cols]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "        ('numeric', 'passthrough', numeric_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=120, random_state=42, n_jobs=-1, min_samples_leaf=2),\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "results = []\n",
        "feature_importances = None\n",
        "\n",
        "for name, model in models.items():\n",
        "    clf = Pipeline(steps=[('preprocess', preprocessor), ('model', model)])\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    results.append({'model': name, 'mae': mae, 'r2': r2})\n",
        "\n",
        "    if name == 'RandomForest':\n",
        "        model_step = clf.named_steps['model']\n",
        "        feat_names = clf.named_steps['preprocess'].get_feature_names_out()\n",
        "        importances = pd.Series(model_step.feature_importances_, index=feat_names)\n",
        "        feature_importances = importances.sort_values(ascending=False).head(15)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "display(results_df)\n",
        "\n",
        "if feature_importances is not None:\n",
        "    display(feature_importances)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f9a55b",
      "metadata": {},
      "source": [
        "## 8) Findings & Next Steps\n",
        "- Price per saleable sqft varies widely; distribution is right-skewed.\n",
        "- Size (gross/saleable area) and district are dominant drivers; macro signals (CPI/unemployment) also contribute.\n",
        "- Random forest outperforms linear regression (higher R?, lower MAE).\n",
        "- Potential extensions: add more granular building/room features, include transaction type, and tune model hyperparameters.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
